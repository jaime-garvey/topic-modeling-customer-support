{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import string\n",
    "import math\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer # or LancasterStemmer, RegexpStemmer, SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "#from textblob import TextBlob as tb\n",
    "\n",
    "import gensim\n",
    "from gensim.models import TfidfModel\n",
    "from gensim import corpora\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "import pyLDAvis\n",
    "from pyLDAvis import gensim as gensimvis #topic modeling\n",
    "\n",
    "#import codecs\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#import mpld3\n",
    "\n",
    "from pprint import pprint\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show full cell contents\n",
    "pd.set_option('display.max_colwidth',-1) \n",
    "\n",
    "# Make better use of Jupyter Notebook cell width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Mongo Data to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'host': 'ec2-18-191-25-42.us-east-2.compute.amazonaws.com', \n",
    "    'username':  'admin',\n",
    "    'password': 'secure_password',\n",
    "    'authSource': 'articles'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "client = MongoClient(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "db = client.articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "client = MongoClient(\"mongodb://admin:secure_password@18.191.25.42:27017\" + \"/?authSource=admin\")\n",
    "db = client.articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.authenticate('admin', 'secure_password')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "blogs = db.blogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "blogs.find_one({});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#save as dataframe\n",
    "blogs_df = pd.DataFrame(list(blogs.find()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "blogs_df.to_pickle(\"./blogs_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. Remove punctuation \n",
    "2. Lowercase\n",
    "3. Tokenize \n",
    "4. Stop words\n",
    "5. Replace numbers\n",
    "6. Lemmatization or Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "blogs_df = pd.read_pickle('blogs_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "text = pd.DataFrame(blogs_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "text.head(1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Check for Null Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "assert text['text'].isnull().count() == len(text['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Statistical Summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_words = text['text'].apply(lambda x: len(x.split()))\n",
    "num_words_mean, num_words_std = np.mean(num_words), np.std(num_words)\n",
    "\n",
    "num_sentences = text['text'].apply(lambda x: len(re.split( '~ ...' ,'~'.join(x.split('.')))))\n",
    "num_sentences_mean = np.mean(num_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#all_words = list(text['text'].str.lower().str.split(' ', expand=True).stack().unique())\n",
    "all_words = list(set(text['text'].apply(lambda x: len(x.lower().split()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Remove punctuation \n",
    "2. Lowercase\n",
    "3. Tokenize \n",
    "4. Stop words\n",
    "5. Replace numbers\n",
    "6. Lemmatization or Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logging.basicConfig(filename='lda_model.log', format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_arr = text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "        \n",
    "\n",
    "clean_sents = list(sent_to_words(text_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_sents;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram & Trigram Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = Phrases(clean_sents, min_count=1, threshold=1)\n",
    "\n",
    "#phrases_trigram = Phrases(clean_sents, min_count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = Phraser(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apple to text\n",
    "for sent in bigram[clean_sents]:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('clean_sents.pkl', 'wb')\n",
    "pickle.dump(clean_sents, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Cleaning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Helper function to clean text\n",
    "\n",
    "default_stemmer = PorterStemmer()\n",
    "default_stopwords = stopwords.words('english') # or any other list of your choice\n",
    "\n",
    "REPLACE_BY_SPACE_RE = re.compile(r'[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile(r'[^0-9a-z #+_]')\n",
    "\n",
    "def clean_text(text, ):\n",
    "\n",
    "    def tokenize_text(text):\n",
    "        return [w for s in sent_tokenize(text) for w in word_tokenize(s)]\n",
    "\n",
    "    def remove_special_characters(text, characters=string.punctuation.replace('-', '')):\n",
    "        #tokens = tokenize_text(text)\n",
    "        text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols (puncuation) by space in text\n",
    "        text = BAD_SYMBOLS_RE.sub('', text)\n",
    "        return text\n",
    "        #pattern = re.compile('[{}]'.format(re.escape(characters)))\n",
    "        #return ' '.join(filter(None, [pattern.sub('', t) for t in tokens]))\n",
    "\n",
    "    def stem_text(text, stemmer= default_stemmer):\n",
    "        tokens = tokenize_text(text)\n",
    "        return ' '.join([stemmer.stem(t) for t in tokens])\n",
    "\n",
    "    def remove_stopwords(text, stop_words=default_stopwords):\n",
    "        tokens = [w for w in tokenize_text(text) if w not in stop_words]\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "    text = text.strip(' ') # strip whitespaces\n",
    "    text = text.lower() # lowercase\n",
    "    text = stem_text(text) # stemming\n",
    "    text = remove_special_characters(text) # remove punctuation and symbols\n",
    "    text = remove_stopwords(text) # remove stopwords\n",
    "    text = re.sub(r'\\d+', 'num', text) #substitute numbers with 'num'\n",
    "    #text.strip(' ') # strip whitespaces again??\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "text = text['text'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# helper function for tokenization\n",
    "def tokenize(text):\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "#     bigrams  = [' '.join(bigram) for bigram in nltk.bigrams(tokens)]\n",
    "#     trigrams = [' '.join(trigram) for trigram in nltk.trigrams(tokens)]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tokens = text.apply(lambda x: tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "token_arr = tokens.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#token_arr[document index][work index]\n",
    "#token_arr[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 abl\n",
      "1 abroad\n",
      "2 account\n",
      "3 actor\n",
      "4 adam\n",
      "5 ago\n",
      "6 alic\n",
      "7 alist\n",
      "8 allegi\n",
      "9 alon\n",
      "10 along\n",
      "11 america\n",
      "12 american\n",
      "13 ami\n",
      "14 amid\n",
      "15 among\n",
      "16 amount\n",
      "17 ani\n",
      "18 anim\n",
      "19 anyon\n",
      "20 anyth\n",
      "21 appar\n",
      "22 arguabl\n",
      "23 assassin\n",
      "24 averag\n",
      "25 awaken\n",
      "26 away\n",
      "27 back\n",
      "28 bad\n",
      "29 becam\n",
      "30 becaus\n",
      "31 becom\n",
      "32 befor\n",
      "33 ben\n",
      "34 benhur\n",
      "35 bet\n",
      "36 better\n",
      "37 beyond\n",
      "38 bfg\n",
      "39 big\n",
      "40 biggest\n",
      "41 billion\n",
      "42 billiondollar\n",
      "43 book\n",
      "44 box\n",
      "45 brad\n",
      "46 budget\n",
      "47 built\n",
      "48 butt\n",
      "49 buy\n",
      "50 came\n",
      "51 camera\n",
      "52 captain\n",
      "53 cent\n",
      "54 certainli\n",
      "55 chang\n",
      "56 chart\n",
      "57 china\n",
      "58 chri\n",
      "59 chunk\n",
      "60 civil\n",
      "61 clear\n",
      "62 colleg\n",
      "63 compel\n",
      "64 confus\n",
      "65 cost\n",
      "66 could\n",
      "67 countri\n",
      "68 cours\n",
      "69 credit\n",
      "70 creed\n",
      "71 current\n",
      "72 date\n",
      "73 day\n",
      "74 decemb\n",
      "75 declar\n",
      "76 denzel\n",
      "77 depp\n",
      "78 despit\n",
      "79 determin\n",
      "80 dirti\n",
      "81 disney\n",
      "82 diverg\n",
      "83 doe\n",
      "84 dog\n",
      "85 domest\n",
      "86 done\n",
      "87 dori\n",
      "88 dragon\n",
      "89 draw\n",
      "90 driven\n",
      "91 dude\n",
      "92 earli\n",
      "93 earlier\n",
      "94 earn\n",
      "95 easier\n",
      "96 eight\n",
      "97 either\n",
      "98 elba\n",
      "99 emma\n",
      "100 empir\n",
      "101 enough\n",
      "102 entertain\n",
      "103 episod\n",
      "104 estim\n",
      "105 even\n",
      "106 ever\n",
      "107 everybodi\n",
      "108 everyth\n",
      "109 explain\n",
      "110 extravag\n",
      "111 fact\n",
      "112 fail\n",
      "113 far\n",
      "114 farm\n",
      "115 felic\n",
      "116 femal\n",
      "117 fenc\n",
      "118 fest\n",
      "119 fewer\n",
      "120 fight\n",
      "121 film\n",
      "122 find\n",
      "123 flail\n",
      "124 flop\n",
      "125 florenc\n",
      "126 footbal\n",
      "127 forc\n",
      "128 formula\n",
      "129 foster\n",
      "130 four\n",
      "131 franchis\n",
      "132 franco\n",
      "133 gari\n",
      "134 get\n",
      "135 ghostbust\n",
      "136 glass\n",
      "137 global\n",
      "138 go\n",
      "139 goe\n",
      "140 good\n",
      "141 gosl\n",
      "142 grandpa\n",
      "143 grant\n",
      "144 greenlight\n",
      "145 guy\n",
      "146 gyllenha\n",
      "147 ha\n",
      "148 hair\n",
      "149 hank\n",
      "150 hard\n",
      "151 help\n",
      "152 hi\n",
      "153 highestgross\n",
      "154 hit\n",
      "155 hollywood\n",
      "156 home\n",
      "157 hous\n",
      "158 huge\n",
      "159 idri\n",
      "160 import\n",
      "161 includ\n",
      "162 independ\n",
      "163 inferno\n",
      "164 inflat\n",
      "165 interest\n",
      "166 jake\n",
      "167 jame\n",
      "168 jenkin\n",
      "169 jennif\n",
      "170 johnni\n",
      "171 jone\n",
      "172 jungl\n",
      "173 juri\n",
      "174 la\n",
      "175 land\n",
      "176 largest\n",
      "177 latest\n",
      "178 lawrenc\n",
      "179 leader\n",
      "180 least\n",
      "181 librari\n",
      "182 life\n",
      "183 like\n",
      "184 limit\n",
      "185 limitedreleas\n",
      "186 liveact\n",
      "187 look\n",
      "188 loser\n",
      "189 made\n",
      "190 make\n",
      "191 mani\n",
      "192 mark\n",
      "193 market\n",
      "194 marketplac\n",
      "195 marque\n",
      "196 marvel\n",
      "197 massiv\n",
      "198 may\n",
      "199 mayb\n",
      "200 mccarthi\n",
      "201 mean\n",
      "202 meanwhil\n",
      "203 melissa\n",
      "204 menu\n",
      "205 meryl\n",
      "206 million\n",
      "207 modest\n",
      "208 money\n",
      "209 month\n",
      "210 movi\n",
      "211 multiplex\n",
      "212 mutant\n",
      "213 name\n",
      "214 neighbor\n",
      "215 never\n",
      "216 nice\n",
      "217 ninja\n",
      "218 nocturn\n",
      "219 none\n",
      "220 north\n",
      "221 note\n",
      "222 nt\n",
      "223 num\n",
      "224 number\n",
      "225 offer\n",
      "226 offic\n",
      "227 one\n",
      "228 onli\n",
      "229 origin\n",
      "230 passeng\n",
      "231 past\n",
      "232 pave\n",
      "233 peak\n",
      "234 percent\n",
      "235 pet\n",
      "236 pete\n",
      "237 pitt\n",
      "238 pixar\n",
      "239 play\n",
      "240 playoff\n",
      "241 popcorn\n",
      "242 power\n",
      "243 pratt\n",
      "244 presenc\n",
      "245 presidentelect\n",
      "246 pretti\n",
      "247 price\n",
      "248 promot\n",
      "249 propel\n",
      "250 protagonist\n",
      "251 protectionist\n",
      "252 pull\n",
      "253 put\n",
      "254 qualiti\n",
      "255 recogn\n",
      "256 record\n",
      "257 releas\n",
      "258 remak\n",
      "259 rememb\n",
      "260 respond\n",
      "261 rest\n",
      "262 resurg\n",
      "263 ridicul\n",
      "264 right\n",
      "265 rise\n",
      "266 rogu\n",
      "267 rule\n",
      "268 ryan\n",
      "269 santa\n",
      "270 sausag\n",
      "271 score\n",
      "272 seat\n",
      "273 second\n",
      "274 secret\n",
      "275 see\n",
      "276 seem\n",
      "277 seen\n",
      "278 sell\n",
      "279 sequel\n",
      "280 seri\n",
      "281 sever\n",
      "282 shadow\n",
      "283 sign\n",
      "284 sinc\n",
      "285 sing\n",
      "286 six\n",
      "287 slip\n",
      "288 smash\n",
      "289 smith\n",
      "290 snapshot\n",
      "291 sold\n",
      "292 solid\n",
      "293 soror\n",
      "294 sorri\n",
      "295 star\n",
      "296 stardriven\n",
      "297 start\n",
      "298 stay\n",
      "299 still\n",
      "300 stiller\n",
      "301 stone\n",
      "302 stop\n",
      "303 stori\n",
      "304 straight\n",
      "305 streep\n",
      "306 studio\n",
      "307 sulli\n",
      "308 summer\n",
      "309 superhero\n",
      "310 sure\n",
      "311 surpass\n",
      "312 susman\n",
      "313 take\n",
      "314 talk\n",
      "315 tast\n",
      "316 teenag\n",
      "317 ten\n",
      "318 testosteron\n",
      "319 theater\n",
      "320 thi\n",
      "321 thing\n",
      "322 third\n",
      "323 thoroughbred\n",
      "324 though\n",
      "325 three\n",
      "326 threequel\n",
      "327 threeweekold\n",
      "328 throughout\n",
      "329 ticket\n",
      "330 ticketbuy\n",
      "331 time\n",
      "332 tireless\n",
      "333 titl\n",
      "334 tom\n",
      "335 top\n",
      "336 total\n",
      "337 tough\n",
      "338 toward\n",
      "339 trade\n",
      "340 trek\n",
      "341 trend\n",
      "342 true\n",
      "343 trump\n",
      "344 turn\n",
      "345 turtl\n",
      "346 two\n",
      "347 unfamiliar\n",
      "348 uninspir\n",
      "349 upon\n",
      "350 viii\n",
      "351 wa\n",
      "352 walt\n",
      "353 want\n",
      "354 war\n",
      "355 warcraft\n",
      "356 washington\n",
      "357 watch\n",
      "358 way\n",
      "359 weak\n",
      "360 week\n",
      "361 weekend\n",
      "362 well\n",
      "363 wellcraft\n",
      "364 welllik\n",
      "365 whi\n",
      "366 whole\n",
      "367 whose\n",
      "368 wide\n",
      "369 win\n",
      "370 winner\n",
      "371 winwin\n",
      "372 women\n",
      "373 work\n",
      "374 worth\n",
      "375 would\n",
      "376 ye\n",
      "377 year\n",
      "378 yet\n",
      "379 zooland\n",
      "380 zootopia\n",
      "381 deuc\n",
      "382 fourth\n",
      "383 last\n",
      "384 mcallist\n",
      "385 reach\n",
      "386 across\n",
      "387 afp\n",
      "388 also\n",
      "389 analysi\n",
      "390 blame\n",
      "391 bst\n",
      "392 busi\n",
      "393 centr\n",
      "394 central\n",
      "395 christma\n",
      "396 compani\n",
      "397 compar\n",
      "398 custom\n",
      "399 dip\n",
      "400 drastic\n",
      "401 drop\n",
      "402 fell\n",
      "403 festiv\n",
      "404 figur\n",
      "405 first\n",
      "406 flock\n",
      "407 footfal\n",
      "408 getti\n",
      "409 half\n",
      "410 high\n",
      "411 hour\n",
      "412 imag\n",
      "413 januari\n",
      "414 jeremi\n",
      "415 london\n",
      "416 monday\n",
      "417 nearli\n",
      "418 new\n",
      "419 open\n",
      "420 peopl\n",
      "421 per\n",
      "422 period\n",
      "423 plummet\n",
      "424 poor\n",
      "425 popular\n",
      "426 read\n",
      "427 reduc\n",
      "428 retail\n",
      "429 run\n",
      "430 sale\n",
      "431 saw\n",
      "432 selwyn\n",
      "433 shop\n",
      "434 shopper\n",
      "435 show\n",
      "436 spend\n",
      "437 spree\n",
      "438 springboard\n",
      "439 street\n",
      "440 uk\n",
      "441 weather\n",
      "442 alex\n",
      "443 alreadi\n",
      "444 alway\n",
      "445 area\n",
      "446 arsen\n",
      "447 attack\n",
      "448 avail\n",
      "449 ball\n",
      "450 basi\n",
      "451 believ\n",
      "452 bit\n",
      "453 boy\n",
      "454 build\n",
      "455 campaign\n",
      "456 come\n",
      "457 confer\n",
      "458 confid\n",
      "459 crystal\n",
      "460 danger\n",
      "461 encourag\n",
      "462 except\n",
      "463 finish\n",
      "464 forget\n",
      "465 front\n",
      "466 game\n",
      "467 giroud\n",
      "468 give\n",
      "469 goal\n",
      "470 hold\n",
      "471 hope\n",
      "472 intern\n",
      "473 iwobi\n",
      "474 jan\n",
      "475 lack\n",
      "476 leagu\n",
      "477 manag\n",
      "478 movement\n",
      "479 must\n",
      "480 net\n",
      "481 nevertheless\n",
      "482 news\n",
      "483 nigeria\n",
      "484 old\n",
      "485 palac\n",
      "486 pass\n",
      "487 pitch\n",
      "488 pm\n",
      "489 premier\n",
      "490 prove\n",
      "491 question\n",
      "492 quick\n",
      "493 recept\n",
      "494 regular\n",
      "495 relat\n",
      "496 say\n",
      "497 scorer\n",
      "498 season\n",
      "499 skill\n",
      "500 somewhat\n",
      "501 state\n",
      "502 stress\n",
      "503 struggl\n",
      "504 sunday\n",
      "505 think\n",
      "506 train\n",
      "507 veri\n",
      "508 versatil\n",
      "509 victori\n",
      "510 wake\n",
      "511 wenger\n",
      "512 word\n",
      "513 young\n",
      "514 aa\n",
      "515 abdulaziz\n",
      "516 abubakar\n",
      "517 abuja\n",
      "518 academ\n",
      "519 acrimoni\n",
      "520 action\n",
      "521 adekunl\n",
      "522 administr\n",
      "523 affair\n",
      "524 ali\n",
      "525 alkhali\n",
      "526 allianc\n",
      "527 alloc\n",
      "528 almost\n",
      "529 amnesti\n",
      "530 ampl\n",
      "531 anayo\n",
      "532 annul\n",
      "533 anpp\n",
      "534 apc\n",
      "535 apga\n",
      "536 april\n",
      "537 argu\n",
      "538 arthur\n",
      "539 ask\n",
      "540 assembl\n",
      "541 assum\n",
      "542 awar\n",
      "543 award\n",
      "544 battl\n",
      "545 behalf\n",
      "546 behead\n",
      "547 belong\n",
      "548 belov\n",
      "549 bill\n",
      "550 blindli\n",
      "551 bloodi\n",
      "552 blow\n",
      "553 bode\n",
      "554 brother\n",
      "555 cabinet\n",
      "556 carri\n",
      "557 case\n",
      "558 celebr\n",
      "559 centuri\n",
      "560 ceremoni\n",
      "561 chair\n",
      "562 chairman\n",
      "563 chamber\n",
      "564 charismat\n",
      "565 chariti\n",
      "566 circul\n",
      "567 clarif\n",
      "568 clearli\n",
      "569 clog\n",
      "570 coffer\n",
      "571 colleagu\n",
      "572 collect\n",
      "573 column\n",
      "574 combin\n",
      "575 commend\n",
      "576 comment\n",
      "577 commiss\n",
      "578 commission\n",
      "579 committe\n",
      "580 conclus\n",
      "581 conduct\n",
      "582 congress\n",
      "583 consciou\n",
      "584 contract\n",
      "585 contradict\n",
      "586 convict\n",
      "587 cooper\n",
      "588 court\n",
      "589 crow\n",
      "590 cut\n",
      "591 deliv\n",
      "592 delta\n",
      "593 deltan\n",
      "594 democrat\n",
      "595 demonstr\n",
      "596 deputi\n",
      "597 deserv\n",
      "598 distinguish\n",
      "599 duti\n",
      "600 dynam\n",
      "601 economi\n",
      "602 economist\n",
      "603 eighth\n",
      "604 elect\n",
      "605 elector\n",
      "606 end\n",
      "607 engin\n",
      "608 ensur\n",
      "609 enviabl\n",
      "610 especi\n",
      "611 everi\n",
      "612 excel\n",
      "613 expenditur\n",
      "614 expert\n",
      "615 express\n",
      "616 famili\n",
      "617 farmer\n",
      "618 favourit\n",
      "619 feed\n",
      "620 financ\n",
      "621 fiveday\n",
      "622 floor\n",
      "623 follow\n",
      "624 former\n",
      "625 forum\n",
      "626 freed\n",
      "627 georg\n",
      "628 given\n",
      "629 govern\n",
      "630 governor\n",
      "631 gown\n",
      "632 graduat\n",
      "633 grand\n",
      "634 group\n",
      "635 guin\n",
      "636 hallow\n",
      "637 happi\n",
      "638 happy\n",
      "639 hardwork\n",
      "640 health\n",
      "641 hear\n",
      "642 histor\n",
      "643 histori\n",
      "644 holiday\n",
      "645 human\n",
      "646 ibori\n",
      "647 ifeanyi\n",
      "648 imo\n",
      "649 inconclus\n",
      "650 indol\n",
      "651 inform\n",
      "652 instinct\n",
      "653 internet\n",
      "654 invest\n",
      "655 jail\n",
      "656 join\n",
      "657 joy\n",
      "658 judici\n",
      "659 juli\n",
      "660 kenya\n",
      "661 knew\n",
      "662 labour\n",
      "663 ladi\n",
      "664 lago\n",
      "665 lakemfa\n",
      "666 landlord\n",
      "667 lead\n",
      "668 leadership\n",
      "669 learn\n",
      "670 learnt\n",
      "671 leav\n",
      "672 legisl\n",
      "673 lesson\n",
      "674 let\n",
      "675 live\n",
      "676 local\n",
      "677 long\n",
      "678 longest\n",
      "679 love\n",
      "680 madam\n",
      "681 mafara\n",
      "682 mainstay\n",
      "683 march\n",
      "684 mere\n",
      "685 ministri\n",
      "686 miss\n",
      "687 moham\n",
      "688 moment\n",
      "689 monasteri\n",
      "690 monthli\n",
      "691 moral\n",
      "692 mosqu\n",
      "693 move\n",
      "694 mrs\n",
      "695 nation\n",
      "696 navig\n",
      "697 ndume\n",
      "698 need\n",
      "699 neither\n",
      "700 next\n",
      "701 nkechi\n",
      "702 nnum\n",
      "703 nobel\n",
      "704 numyear\n",
      "705 occupi\n",
      "706 okorocha\n",
      "707 okowa\n",
      "708 onanef\n",
      "709 onc\n",
      "710 openli\n",
      "711 orderli\n",
      "712 organis\n",
      "713 owe\n",
      "714 owei\n",
      "715 paid\n",
      "716 panel\n",
      "717 parliament\n",
      "718 parti\n",
      "719 pay\n",
      "720 pdp\n",
      "721 person\n",
      "722 place\n",
      "723 pledg\n",
      "724 point\n",
      "725 polic\n",
      "726 polici\n",
      "727 polit\n",
      "728 politician\n",
      "729 portfolio\n",
      "730 posit\n",
      "731 post\n",
      "732 postpon\n",
      "733 prioriti\n",
      "734 prison\n",
      "735 prize\n",
      "736 probe\n",
      "737 product\n",
      "738 progress\n",
      "739 project\n",
      "740 provid\n",
      "741 public\n",
      "742 quit\n",
      "743 rate\n",
      "744 rather\n",
      "745 receiv\n",
      "746 regard\n",
      "747 reiter\n",
      "748 rejoin\n",
      "749 remain\n",
      "750 render\n",
      "751 report\n",
      "752 rerun\n",
      "753 return\n",
      "754 river\n",
      "755 road\n",
      "756 rocha\n",
      "757 roll\n",
      "758 roof\n",
      "759 sail\n",
      "760 salari\n",
      "761 scene\n",
      "762 school\n",
      "763 secretari\n",
      "764 secretariat\n",
      "765 sector\n",
      "766 seek\n",
      "767 senat\n",
      "768 serv\n",
      "769 servic\n",
      "770 set\n",
      "771 seven\n",
      "772 seventeen\n",
      "773 sew\n",
      "774 shatiman\n",
      "775 ship\n",
      "776 smart\n",
      "777 snarp\n",
      "778 son\n",
      "779 soothsay\n",
      "780 spare\n",
      "781 spent\n",
      "782 split\n",
      "783 steal\n",
      "784 stream\n",
      "785 studi\n",
      "786 style\n",
      "787 subsidis\n",
      "788 suggest\n",
      "789 summaris\n",
      "790 superintend\n",
      "791 survivalist\n",
      "792 taekwondo\n",
      "793 teacher\n",
      "794 tear\n",
      "795 technic\n",
      "796 televis\n",
      "797 thirti\n",
      "798 told\n",
      "799 took\n",
      "800 trader\n",
      "801 transport\n",
      "802 travel\n",
      "803 truth\n",
      "804 tyre\n",
      "805 unnecessari\n",
      "806 unschool\n",
      "807 version\n",
      "808 violenc\n",
      "809 vocat\n",
      "810 wage\n",
      "811 water\n",
      "812 wednesday\n",
      "813 weekli\n",
      "814 wife\n",
      "815 wish\n",
      "816 wit\n",
      "817 without\n",
      "818 worker\n",
      "819 world\n",
      "820 wrestl\n",
      "821 yari\n",
      "822 zamfara\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(token_arr)\n",
    "\n",
    "count = 0\n",
    "for k,v in dictionary.iteritems():\n",
    "    print(k,v)\n",
    "    count += 1\n",
    "    #if count > 10:\n",
    "       # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "dictionary.filter_extremes(no_below=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Create dictionary for each document with words and frequency\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in token_arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bow_corpus;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.04256282653793743),\n",
      " (1, 0.04256282653793743),\n",
      " (2, 0.04256282653793743),\n",
      " (3, 0.04256282653793743),\n",
      " (4, 0.04256282653793743),\n",
      " (5, 0.04256282653793743),\n",
      " (6, 0.04256282653793743),\n",
      " (7, 0.04256282653793743),\n",
      " (8, 0.08512565307587486),\n",
      " (9, 0.12768847961381227),\n",
      " (10, 0.04256282653793743),\n",
      " (11, 0.04256282653793743),\n",
      " (12, 0.04256282653793743),\n",
      " (13, 0.17025130615174972),\n",
      " (14, 0.04256282653793743),\n",
      " (15, 0.04256282653793743),\n",
      " (16, 0.04256282653793743),\n",
      " (17, 0.08512565307587486),\n",
      " (18, 0.04256282653793743),\n",
      " (19, 0.04256282653793743),\n",
      " (20, 0.04256282653793743),\n",
      " (21, 0.04256282653793743),\n",
      " (22, 0.04256282653793743),\n",
      " (23, 0.04256282653793743),\n",
      " (24, 0.04256282653793743),\n",
      " (25, 0.12768847961381227),\n",
      " (26, 0.04256282653793743),\n",
      " (27, 0.04256282653793743),\n",
      " (28, 0.04256282653793743),\n",
      " (29, 0.04256282653793743),\n",
      " (30, 0.04256282653793743),\n",
      " (31, 0.04256282653793743),\n",
      " (32, 0.12768847961381227),\n",
      " (33, 0.21281413268968716),\n",
      " (34, 0.04256282653793743),\n",
      " (35, 0.04256282653793743),\n",
      " (36, 0.12768847961381227),\n",
      " (37, 0.7235680511449363),\n",
      " (38, 0.04256282653793743),\n",
      " (39, 0.04256282653793743),\n",
      " (40, 0.08512565307587486),\n",
      " (41, 0.04256282653793743),\n",
      " (42, 0.04256282653793743),\n",
      " (43, 0.08512565307587486),\n",
      " (44, 0.04256282653793743),\n",
      " (45, 0.12768847961381227),\n",
      " (46, 0.21281413268968716),\n",
      " (47, 0.04256282653793743),\n",
      " (48, 0.08512565307587486),\n",
      " (49, 0.04256282653793743),\n",
      " (50, 0.04256282653793743),\n",
      " (51, 0.04256282653793743),\n",
      " (52, 0.04256282653793743),\n",
      " (53, 0.04256282653793743),\n",
      " (54, 0.04256282653793743),\n",
      " (55, 0.04256282653793743),\n",
      " (56, 0.25537695922762454),\n",
      " (57, 0.04256282653793743),\n",
      " (58, 0.08512565307587486),\n",
      " (59, 0.04256282653793743),\n",
      " (60, 0.04256282653793743),\n",
      " (61, 0.17025130615174972),\n",
      " (62, 0.08512565307587486),\n",
      " (63, 0.04256282653793743),\n",
      " (64, 0.04256282653793743),\n",
      " (65, 0.08512565307587486),\n",
      " (66, 0.17025130615174972),\n",
      " (67, 0.04256282653793743),\n",
      " (68, 0.04256282653793743),\n",
      " (69, 0.04256282653793743),\n",
      " (70, 0.04256282653793743),\n",
      " (71, 0.04256282653793743)]\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# from gensim import corpora\n",
    "# # Creating term dictionary of corpus, where each unique term is assigned an index. \n",
    "# dictionary = corpora.Dictionary(doc_clean)\n",
    " \n",
    "# # Filter terms which occurs in less than 4 articles & more than 40% of the articles \n",
    "# #dictionary.filter_extremes(no_below=4, no_above=0.4)\n",
    " \n",
    "# # List of few words which are removed from dictionary as they are content neutral\n",
    "# stoplist = set('also use make people know many call include part find become like mean often different \\\n",
    "#                usually take wikt come give well get since type list say change see refer actually iii \\\n",
    "#                aisne kinds pas ask would way something need things want every str'.split())\n",
    "# stop_ids = [dictionary.token2id[stopword] for stopword in stoplist if stopword in dictionary.token2id]\n",
    "# dictionary.filter_tokens(stop_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# LDA (Bag of Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.059*\"million\" + 0.024*\"one\" + 0.022*\"still\" + 0.019*\"made\" + 0.019*\"market\" + 0.018*\"weekend\" + 0.017*\"current\" + 0.017*\"offic\" + 0.016*\"tast\" + 0.015*\"top\"\n",
      "Topic: 1 \n",
      "Words: 0.025*\"state\" + 0.014*\"work\" + 0.012*\"includ\" + 0.012*\"civil\" + 0.012*\"nigeria\" + 0.012*\"two\" + 0.012*\"way\" + 0.012*\"releas\" + 0.011*\"even\" + 0.011*\"ani\"\n",
      "Topic: 2 \n",
      "Words: 0.116*\"million\" + 0.043*\"still\" + 0.037*\"made\" + 0.035*\"one\" + 0.029*\"current\" + 0.029*\"top\" + 0.028*\"weekend\" + 0.022*\"like\" + 0.022*\"offic\" + 0.021*\"box\"\n",
      "Topic: 3 \n",
      "Words: 0.011*\"reach\" + 0.011*\"mark\" + 0.011*\"new\" + 0.011*\"saw\" + 0.011*\"score\" + 0.011*\"state\" + 0.011*\"million\" + 0.011*\"number\" + 0.011*\"come\" + 0.011*\"cent\"\n",
      "Topic: 4 \n",
      "Words: 0.137*\"state\" + 0.044*\"work\" + 0.031*\"nigeria\" + 0.026*\"two\" + 0.026*\"includ\" + 0.020*\"offic\" + 0.020*\"made\" + 0.020*\"civil\" + 0.020*\"even\" + 0.020*\"three\"\n",
      "Topic: 5 \n",
      "Words: 0.088*\"cent\" + 0.087*\"saw\" + 0.085*\"number\" + 0.084*\"new\" + 0.031*\"spend\" + 0.031*\"weekend\" + 0.031*\"run\" + 0.031*\"period\" + 0.031*\"monday\" + 0.031*\"reduc\"\n",
      "Topic: 6 \n",
      "Words: 0.049*\"state\" + 0.046*\"million\" + 0.022*\"made\" + 0.021*\"work\" + 0.017*\"two\" + 0.017*\"nigeria\" + 0.017*\"like\" + 0.016*\"decemb\" + 0.016*\"includ\" + 0.015*\"offic\"\n",
      "Topic: 7 \n",
      "Words: 0.011*\"reach\" + 0.011*\"mark\" + 0.011*\"state\" + 0.011*\"number\" + 0.011*\"saw\" + 0.011*\"score\" + 0.011*\"new\" + 0.011*\"million\" + 0.011*\"come\" + 0.011*\"cent\"\n",
      "Topic: 8 \n",
      "Words: 0.144*\"score\" + 0.049*\"qualiti\" + 0.049*\"well\" + 0.049*\"come\" + 0.026*\"offer\" + 0.026*\"sign\" + 0.026*\"second\" + 0.026*\"must\" + 0.026*\"veri\" + 0.026*\"becom\"\n",
      "Topic: 9 \n",
      "Words: 0.035*\"state\" + 0.027*\"new\" + 0.021*\"number\" + 0.015*\"saw\" + 0.014*\"read\" + 0.014*\"cent\" + 0.014*\"work\" + 0.014*\"nigeria\" + 0.014*\"first\" + 0.013*\"compar\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# LDA (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.074*\"mark\" + 0.074*\"reach\" + 0.009*\"score\" + 0.009*\"million\" + 0.009*\"state\" + 0.009*\"number\" + 0.009*\"saw\" + 0.009*\"new\" + 0.009*\"come\" + 0.009*\"cent\"\n",
      "Topic: 1 Word: 0.040*\"cent\" + 0.040*\"new\" + 0.040*\"number\" + 0.040*\"saw\" + 0.018*\"fewer\" + 0.018*\"monday\" + 0.018*\"run\" + 0.018*\"reduc\" + 0.018*\"london\" + 0.018*\"compar\"\n",
      "Topic: 2 Word: 0.011*\"mark\" + 0.011*\"reach\" + 0.011*\"score\" + 0.011*\"million\" + 0.011*\"state\" + 0.011*\"number\" + 0.011*\"saw\" + 0.011*\"new\" + 0.011*\"qualiti\" + 0.011*\"cent\"\n",
      "Topic: 3 Word: 0.011*\"mark\" + 0.011*\"reach\" + 0.011*\"score\" + 0.011*\"number\" + 0.011*\"state\" + 0.011*\"saw\" + 0.011*\"million\" + 0.011*\"new\" + 0.011*\"cent\" + 0.011*\"veri\"\n",
      "Topic: 4 Word: 0.047*\"score\" + 0.044*\"million\" + 0.021*\"top\" + 0.021*\"well\" + 0.021*\"qualiti\" + 0.019*\"still\" + 0.019*\"guy\" + 0.018*\"come\" + 0.017*\"one\" + 0.017*\"made\"\n",
      "Topic: 5 Word: 0.011*\"mark\" + 0.011*\"reach\" + 0.011*\"score\" + 0.011*\"state\" + 0.011*\"saw\" + 0.011*\"million\" + 0.011*\"number\" + 0.011*\"new\" + 0.011*\"qualiti\" + 0.011*\"cent\"\n",
      "Topic: 6 Word: 0.060*\"state\" + 0.024*\"work\" + 0.019*\"nigeria\" + 0.017*\"includ\" + 0.017*\"two\" + 0.014*\"releas\" + 0.014*\"decemb\" + 0.014*\"three\" + 0.014*\"way\" + 0.014*\"even\"\n",
      "Topic: 7 Word: 0.011*\"mark\" + 0.011*\"reach\" + 0.011*\"score\" + 0.011*\"state\" + 0.011*\"number\" + 0.011*\"million\" + 0.011*\"cent\" + 0.011*\"saw\" + 0.011*\"new\" + 0.011*\"qualiti\"\n",
      "Topic: 8 Word: 0.011*\"reach\" + 0.011*\"mark\" + 0.011*\"score\" + 0.011*\"million\" + 0.011*\"number\" + 0.011*\"saw\" + 0.011*\"state\" + 0.011*\"new\" + 0.011*\"cent\" + 0.011*\"nigeria\"\n",
      "Topic: 9 Word: 0.011*\"mark\" + 0.011*\"reach\" + 0.011*\"score\" + 0.011*\"million\" + 0.011*\"number\" + 0.011*\"state\" + 0.011*\"saw\" + 0.011*\"cent\" + 0.011*\"come\" + 0.011*\"new\"\n"
     ]
    }
   ],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)\n",
    "\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create the bag of words feature matrix\n",
    "count = CountVectorizer()\n",
    "bag_of_words = count.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Show feature matrix\n",
    "bag_of_words.toarray();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get feature names\n",
    "feature_names = count.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create data frame\n",
    "words = pd.DataFrame(bag_of_words.toarray(), index = posts_df['title'], columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>abdulaziz</th>\n",
       "      <th>abl</th>\n",
       "      <th>abroad</th>\n",
       "      <th>abubakar</th>\n",
       "      <th>abuja</th>\n",
       "      <th>academ</th>\n",
       "      <th>account</th>\n",
       "      <th>acrimoni</th>\n",
       "      <th>across</th>\n",
       "      <th>...</th>\n",
       "      <th>would</th>\n",
       "      <th>wrestl</th>\n",
       "      <th>yari</th>\n",
       "      <th>ye</th>\n",
       "      <th>year</th>\n",
       "      <th>yet</th>\n",
       "      <th>young</th>\n",
       "      <th>zamfara</th>\n",
       "      <th>zooland</th>\n",
       "      <th>zootopia</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>The 8 Biggest Box Office Winners (and Losers) of 2016</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mark Ingram reaches 1,000 rushing yards; first for Saints since 2006</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&amp;apos;Drastic drop&amp;apos; in New Year&amp;apos;s Day sales shoppers across UK as number of customers plummets by half</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iwobi bound to score more goals - Wenger</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rolling into 2017 Nigeria ‘stylee’</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 823 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                  aa  \\\n",
       "title                                                                                                                  \n",
       "The 8 Biggest Box Office Winners (and Losers) of 2016                                                             0    \n",
       "Mark Ingram reaches 1,000 rushing yards; first for Saints since 2006                                              0    \n",
       "&apos;Drastic drop&apos; in New Year&apos;s Day sales shoppers across UK as number of customers plummets by half  0    \n",
       "Iwobi bound to score more goals - Wenger                                                                          0    \n",
       "Rolling into 2017 Nigeria ‘stylee’                                                                                1    \n",
       "\n",
       "                                                                                                                  abdulaziz  \\\n",
       "title                                                                                                                         \n",
       "The 8 Biggest Box Office Winners (and Losers) of 2016                                                             0           \n",
       "Mark Ingram reaches 1,000 rushing yards; first for Saints since 2006                                              0           \n",
       "&apos;Drastic drop&apos; in New Year&apos;s Day sales shoppers across UK as number of customers plummets by half  0           \n",
       "Iwobi bound to score more goals - Wenger                                                                          0           \n",
       "Rolling into 2017 Nigeria ‘stylee’                                                                                1           \n",
       "\n",
       "                                                                                                                  abl  \\\n",
       "title                                                                                                                   \n",
       "The 8 Biggest Box Office Winners (and Losers) of 2016                                                             1     \n",
       "Mark Ingram reaches 1,000 rushing yards; first for Saints since 2006                                              0     \n",
       "&apos;Drastic drop&apos; in New Year&apos;s Day sales shoppers across UK as number of customers plummets by half  0     \n",
       "Iwobi bound to score more goals - Wenger                                                                          0     \n",
       "Rolling into 2017 Nigeria ‘stylee’                                                                                1     \n",
       "\n",
       "                                                                                                                  abroad  \\\n",
       "title                                                                                                                      \n",
       "The 8 Biggest Box Office Winners (and Losers) of 2016                                                             1        \n",
       "Mark Ingram reaches 1,000 rushing yards; first for Saints since 2006                                              0        \n",
       "&apos;Drastic drop&apos; in New Year&apos;s Day sales shoppers across UK as number of customers plummets by half  0        \n",
       "Iwobi bound to score more goals - Wenger                                                                          0        \n",
       "Rolling into 2017 Nigeria ‘stylee’                                                                                0        \n",
       "\n",
       "                                                                                                                  abubakar  \\\n",
       "title                                                                                                                        \n",
       "The 8 Biggest Box Office Winners (and Losers) of 2016                                                             0          \n",
       "Mark Ingram reaches 1,000 rushing yards; first for Saints since 2006                                              0          \n",
       "&apos;Drastic drop&apos; in New Year&apos;s Day sales shoppers across UK as number of customers plummets by half  0          \n",
       "Iwobi bound to score more goals - Wenger                                                                          0          \n",
       "Rolling into 2017 Nigeria ‘stylee’                                                                                1          \n",
       "\n",
       "                                                                                                                  abuja  \\\n",
       "title                                                                                                                     \n",
       "The 8 Biggest Box Office Winners (and Losers) of 2016                                                             0       \n",
       "Mark Ingram reaches 1,000 rushing yards; first for Saints since 2006                                              0       \n",
       "&apos;Drastic drop&apos; in New Year&apos;s Day sales shoppers across UK as number of customers plummets by half  0       \n",
       "Iwobi bound to score more goals - Wenger                                                                          0       \n",
       "Rolling into 2017 Nigeria ‘stylee’                                                                                1       \n",
       "\n",
       "                                                                                                                  academ  \\\n",
       "title                                                                                                                      \n",
       "The 8 Biggest Box Office Winners (and Losers) of 2016                                                             0        \n",
       "Mark Ingram reaches 1,000 rushing yards; first for Saints since 2006                                              0        \n",
       "&apos;Drastic drop&apos; in New Year&apos;s Day sales shoppers across UK as number of customers plummets by half  0        \n",
       "Iwobi bound to score more goals - Wenger                                                                          0        \n",
       "Rolling into 2017 Nigeria ‘stylee’                                                                                1        \n",
       "\n",
       "                                                                                                                  account  \\\n",
       "title                                                                                                                       \n",
       "The 8 Biggest Box Office Winners (and Losers) of 2016                                                             2         \n",
       "Mark Ingram reaches 1,000 rushing yards; first for Saints since 2006                                              0         \n",
       "&apos;Drastic drop&apos; in New Year&apos;s Day sales shoppers across UK as number of customers plummets by half  0         \n",
       "Iwobi bound to score more goals - Wenger                                                                          0         \n",
       "Rolling into 2017 Nigeria ‘stylee’                                                                                0         \n",
       "\n",
       "                                                                                                                  acrimoni  \\\n",
       "title                                                                                                                        \n",
       "The 8 Biggest Box Office Winners (and Losers) of 2016                                                             0          \n",
       "Mark Ingram reaches 1,000 rushing yards; first for Saints since 2006                                              0          \n",
       "&apos;Drastic drop&apos; in New Year&apos;s Day sales shoppers across UK as number of customers plummets by half  0          \n",
       "Iwobi bound to score more goals - Wenger                                                                          0          \n",
       "Rolling into 2017 Nigeria ‘stylee’                                                                                1          \n",
       "\n",
       "                                                                                                                  across  \\\n",
       "title                                                                                                                      \n",
       "The 8 Biggest Box Office Winners (and Losers) of 2016                                                             0        \n",
       "Mark Ingram reaches 1,000 rushing yards; first for Saints since 2006                                              0        \n",
       "&apos;Drastic drop&apos; in New Year&apos;s Day sales shoppers across UK as number of customers plummets by half  1        \n",
       "Iwobi bound to score more goals - Wenger                                                                          0        \n",
       "Rolling into 2017 Nigeria ‘stylee’                                                                                0        \n",
       "\n",
       "                                                                                                                  ...  \\\n",
       "title                                                                                                             ...   \n",
       "The 8 Biggest Box Office Winners (and Losers) of 2016                                                             ...   \n",
       "Mark Ingram reaches 1,000 rushing yards; first for Saints since 2006                                              ...   \n",
       "&apos;Drastic drop&apos; in New Year&apos;s Day sales shoppers across UK as number of customers plummets by half  ...   \n",
       "Iwobi bound to score more goals - Wenger                                                                          ...   \n",
       "Rolling into 2017 Nigeria ‘stylee’                                                                                ...   \n",
       "\n",
       "                                                                                                                  would  \\\n",
       "title                                                                                                                     \n",
       "The 8 Biggest Box Office Winners (and Losers) of 2016                                                             1       \n",
       "Mark Ingram reaches 1,000 rushing yards; first for Saints since 2006                                              0       \n",
       "&apos;Drastic drop&apos; in New Year&apos;s Day sales shoppers across UK as number of customers plummets by half  0       \n",
       "Iwobi bound to score more goals - Wenger                                                                          0       \n",
       "Rolling into 2017 Nigeria ‘stylee’                                                                                0       \n",
       "\n",
       "                                                                                                                  wrestl  \\\n",
       "title                                                                                                                      \n",
       "The 8 Biggest Box Office Winners (and Losers) of 2016                                                             0        \n",
       "Mark Ingram reaches 1,000 rushing yards; first for Saints since 2006                                              0        \n",
       "&apos;Drastic drop&apos; in New Year&apos;s Day sales shoppers across UK as number of customers plummets by half  0        \n",
       "Iwobi bound to score more goals - Wenger                                                                          0        \n",
       "Rolling into 2017 Nigeria ‘stylee’                                                                                1        \n",
       "\n",
       "                                                                                                                  yari  \\\n",
       "title                                                                                                                    \n",
       "The 8 Biggest Box Office Winners (and Losers) of 2016                                                             0      \n",
       "Mark Ingram reaches 1,000 rushing yards; first for Saints since 2006                                              0      \n",
       "&apos;Drastic drop&apos; in New Year&apos;s Day sales shoppers across UK as number of customers plummets by half  0      \n",
       "Iwobi bound to score more goals - Wenger                                                                          0      \n",
       "Rolling into 2017 Nigeria ‘stylee’                                                                                1      \n",
       "\n",
       "                                                                                                                  ye  \\\n",
       "title                                                                                                                  \n",
       "The 8 Biggest Box Office Winners (and Losers) of 2016                                                             1    \n",
       "Mark Ingram reaches 1,000 rushing yards; first for Saints since 2006                                              0    \n",
       "&apos;Drastic drop&apos; in New Year&apos;s Day sales shoppers across UK as number of customers plummets by half  0    \n",
       "Iwobi bound to score more goals - Wenger                                                                          0    \n",
       "Rolling into 2017 Nigeria ‘stylee’                                                                                0    \n",
       "\n",
       "                                                                                                                  year  \\\n",
       "title                                                                                                                    \n",
       "The 8 Biggest Box Office Winners (and Losers) of 2016                                                             14     \n",
       "Mark Ingram reaches 1,000 rushing yards; first for Saints since 2006                                              0      \n",
       "&apos;Drastic drop&apos; in New Year&apos;s Day sales shoppers across UK as number of customers plummets by half  5      \n",
       "Iwobi bound to score more goals - Wenger                                                                          1      \n",
       "Rolling into 2017 Nigeria ‘stylee’                                                                                7      \n",
       "\n",
       "                                                                                                                  yet  \\\n",
       "title                                                                                                                   \n",
       "The 8 Biggest Box Office Winners (and Losers) of 2016                                                             1     \n",
       "Mark Ingram reaches 1,000 rushing yards; first for Saints since 2006                                              0     \n",
       "&apos;Drastic drop&apos; in New Year&apos;s Day sales shoppers across UK as number of customers plummets by half  0     \n",
       "Iwobi bound to score more goals - Wenger                                                                          0     \n",
       "Rolling into 2017 Nigeria ‘stylee’                                                                                0     \n",
       "\n",
       "                                                                                                                  young  \\\n",
       "title                                                                                                                     \n",
       "The 8 Biggest Box Office Winners (and Losers) of 2016                                                             0       \n",
       "Mark Ingram reaches 1,000 rushing yards; first for Saints since 2006                                              0       \n",
       "&apos;Drastic drop&apos; in New Year&apos;s Day sales shoppers across UK as number of customers plummets by half  0       \n",
       "Iwobi bound to score more goals - Wenger                                                                          1       \n",
       "Rolling into 2017 Nigeria ‘stylee’                                                                                0       \n",
       "\n",
       "                                                                                                                  zamfara  \\\n",
       "title                                                                                                                       \n",
       "The 8 Biggest Box Office Winners (and Losers) of 2016                                                             0         \n",
       "Mark Ingram reaches 1,000 rushing yards; first for Saints since 2006                                              0         \n",
       "&apos;Drastic drop&apos; in New Year&apos;s Day sales shoppers across UK as number of customers plummets by half  0         \n",
       "Iwobi bound to score more goals - Wenger                                                                          0         \n",
       "Rolling into 2017 Nigeria ‘stylee’                                                                                1         \n",
       "\n",
       "                                                                                                                  zooland  \\\n",
       "title                                                                                                                       \n",
       "The 8 Biggest Box Office Winners (and Losers) of 2016                                                             1         \n",
       "Mark Ingram reaches 1,000 rushing yards; first for Saints since 2006                                              0         \n",
       "&apos;Drastic drop&apos; in New Year&apos;s Day sales shoppers across UK as number of customers plummets by half  0         \n",
       "Iwobi bound to score more goals - Wenger                                                                          0         \n",
       "Rolling into 2017 Nigeria ‘stylee’                                                                                0         \n",
       "\n",
       "                                                                                                                  zootopia  \n",
       "title                                                                                                                       \n",
       "The 8 Biggest Box Office Winners (and Losers) of 2016                                                             2         \n",
       "Mark Ingram reaches 1,000 rushing yards; first for Saints since 2006                                              0         \n",
       "&apos;Drastic drop&apos; in New Year&apos;s Day sales shoppers across UK as number of customers plummets by half  0         \n",
       "Iwobi bound to score more goals - Wenger                                                                          0         \n",
       "Rolling into 2017 Nigeria ‘stylee’                                                                                0         \n",
       "\n",
       "[5 rows x 823 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "cell_style": "center",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#functions for TD-IDF / BM25\n",
    "def tf(word, doc):\n",
    "    return doc.count(word) / len(doc)\n",
    "\n",
    "def n_containing(word, doclist):\n",
    "    return sum(1 for doc in doclist if word in doc)\n",
    "\n",
    "def idf(word, doclist):\n",
    "    return math.log(len(doclist) / (0.01 + n_containing(word, doclist)))\n",
    "\n",
    "def tfidf(word, doc, doclist):\n",
    "    return (tf(word, doc) * idf(word, doclist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create dictonary of words\n",
    "\n",
    "plottest = plot_data[0][0:1000]\n",
    "\n",
    "worddic = {}\n",
    "\n",
    "for doc in plottest:\n",
    "    for word in wordsunique:\n",
    "        if word in doc:\n",
    "            word = str(word)\n",
    "            index = plottest.index(doc)\n",
    "            positions = list(np.where(np.array(plottest[index]) == word)[0])\n",
    "            idfs = tfidf(word,doc,plottest)\n",
    "            try:\n",
    "                worddic[word].append([index,positions,idfs])\n",
    "            except:\n",
    "                worddic[word] = []\n",
    "                worddic[word].append([index,positions,idfs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# the index creates a dic with each word as a KEY and a list of doc indexs, word positions, and td-idf score as VALUES\n",
    "#worddic['china']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pickel (save) the dictonary to avoid re-calculating\n",
    "np.save('worddic.npy', worddic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp_env]",
   "language": "python",
   "name": "conda-env-nlp_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "277px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
